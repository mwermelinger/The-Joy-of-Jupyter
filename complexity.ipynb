{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithmic complexity\n",
    "\n",
    "This notebook is part of [_The Joy of Jupyter_](https://github.com/mwermelinger/The-Joy-of-Jupyter), an introduction on how to use Jupyter notebooks and what can be done with them.\n",
    "\n",
    "It shows how to obtain the run-time complexity of an algorithm in an empirical way. \n",
    "\n",
    "Almost every code cell in this notebook will take several seconds to execute. It is best to run one cell at a time, instead of doing 'Run All'. \n",
    "\n",
    "## Introduction\n",
    "\n",
    "The run-time complexity of an algorithm is a measure of how the run-time of an algorithm grows when the input size grows. A low complexity indicates an efficient algorithm that is able to cope with increasingly larger inputs.\n",
    "\n",
    "To empirically obtain the complexity of an algorithm, run it (or more precisely, run the code that implements the algorithm) several times for increasing input sizes and see how the run-times grow. This can be done using the `%timeit` command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.9 ns ± 0.219 ns per loop (mean ± std. dev. of 7 runs, 100000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit 4*9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It takes about 16 nanoseconds to add 4 and 9 together. A nanosecond is one billionth of a second, and a microsecond is a millionth of a second. There are 1000 nanoseconds in a microsecond. \n",
    "\n",
    "To reliably measure such a fast operation, it was executed 100 million times. The total time was divided by 100 million to get the time of a single addition operation. This was repeated 7 times to obtain the mean time. This is to allow for variations due to other processes running on the computer.\n",
    "\n",
    "Therefore the above code cell took about 16 ns × 100 million iterations × 7 runs = 0.016 microseconds × 100 million × 7 = 1.6s × 7 ≈ 11 seconds to execute on my machine. You will almost certainly get a different time for the addition operation, as it depends on the machine you're using and what else is running on it. \n",
    "\n",
    "That's why complexity is measured in a machine-independent way by looking at the growth rate of the run-times, and not the absolute values by themselves.\n",
    "\n",
    "The run-time may also depend on the form of the input, not just its size. It is therefore necessary to distinguish between best, average and worst cases. A best (resp. worst) case for the same input size is when the input is such that the algorithm will take the shortest (resp. longest) time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constant complexity\n",
    "\n",
    "An algorithm has constant complexity if the run-time doesn't grow when the input size grows, or in other words, if the run-time remains the same no matter what the input size is. This is the best complexity possible, and is usually only achievable for best cases of some algorithms.\n",
    "\n",
    "An example is searching for the first item in a list: no matter how long the list is, it will always be immediately found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37.1 ns ± 0.29 ns per loop (mean ± std. dev. of 7 runs, 10000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "numbers = [0]\n",
    "%timeit 0 in numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37.4 ns ± 0.778 ns per loop (mean ± std. dev. of 7 runs, 10000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "numbers = [0, 1, 2, 3, 4]\n",
    "%timeit 0 in numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37.2 ns ± 0.21 ns per loop (mean ± std. dev. of 7 runs, 10000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "numbers = [n for n in range(1000)]\n",
    "%timeit 0 in numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, no matter whether the list has one, five or thousand numbers, it always takes about the same time to determine if 0 is in the list, because it's always the first number of each list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Linear complexity\n",
    "\n",
    "An algorithm has linear complexity if its run-time is directly proportional to the input size: if the input size doubles, so does the run-time. \n",
    "\n",
    "For example, if the number to search for is the last one in the list, then the whole list has to be gone through and therefore the run-time will be proportional to the list length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74.5 ns ± 5.22 ns per loop (mean ± std. dev. of 7 runs, 10000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "length = 1\n",
    "numbers = [n for n in range(length)]\n",
    "%timeit length-1 in numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131 ns ± 8.48 ns per loop (mean ± std. dev. of 7 runs, 10000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "length = 5\n",
    "numbers = [n for n in range(length)]\n",
    "%timeit length-1 in numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.3 µs ± 124 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "length = 1000\n",
    "numbers = [n for n in range(length)]\n",
    "%timeit length-1 in numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If it takes 64 nanoseconds for finding the last number in a list of length 1, then it should take 5 × 64 = 320 nanoseconds for a list of length 5, and 64000 nanoseconds (or 64 microseconds) for a list of length 1000. The actual timings are however much lower. \n",
    "\n",
    "The time value for a list of length 1 is very odd, because it's the essentially the same operation as before (`0 in [0]`) and hence should have taken 33 nanoseconds. Even with that value, the timings for lengths 5 and 1000 are lower than expected. That may indicate that there are some extra operations, e.g. to set up the search and return the Boolean result, taking longer than the actual search in short lists. It's thus best to take timings for larger inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26.2 µs ± 337 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "length = 2000\n",
    "numbers = [n for n in range(length)]\n",
    "%timeit length-1 in numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can see that the run-time practically doubled when the list length doubled.\n",
    "\n",
    "**Activity:** To be more confident of the linear complexity, keep doubling the input size a few more times and check the resulting times.\n",
    "\n",
    "To sum up, searching for an item in a list has constant complexity in the best case and linear complexity in the worst case.\n",
    "\n",
    "**Activity:** Is searching for a non-existent item a best case or a worst case? Explain your hypothesis and test it by changing the above experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logarithmic complexity\n",
    "\n",
    "An algorithm has logarithmic complexity if the run-time increases by a fixed amount when the input size doubles. \n",
    "A classic example is using [binary search](https://en.wikipedia.org/wiki/Binary_search_algorithm) to look for an item in an already sorted list of items. \n",
    "The following code was taken from [_The M269 Library_](http://tiny.cc/m269-library)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def binary_search(items, item):\n",
    "    \"\"\"Return True if items includes the item, otherwise False.\n",
    "\n",
    "    Assume the items are in non-decreasing order.\n",
    "    Assume item and items are all of the same type.\n",
    "    \"\"\"\n",
    "    first = 0\n",
    "    last = len(items) - 1\n",
    "    while first <= last:\n",
    "        # Base case: the item is in the middle.\n",
    "        middle = (first + last) // 2\n",
    "        if items[middle] == item:\n",
    "            return True\n",
    "        # Reduction step: find the half where the item should be.\n",
    "        elif items[middle] < item:\n",
    "            # The item must be above the middle position.\n",
    "            first = middle + 1\n",
    "        else:\n",
    "            # The item must be below the middle position.\n",
    "            last = middle - 1\n",
    "    # Base case: the search space is empty.\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An average case is to search for a random number that exists in the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.82 µs ± 118 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "size = 1000\n",
    "numbers = [n for n in range(size)]\n",
    "%timeit binary_search(numbers, randint(0, size - 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.96 µs ± 203 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "numbers = [n for n in range(size * 2)]\n",
    "%timeit binary_search(numbers, randint(0, size*2 - 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.56 µs ± 115 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "numbers = [n for n in range(size * 4)]\n",
    "%timeit binary_search(numbers, randint(0, size*4 - 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doubling the input size increases the time by a very small amount. The reason is that it only takes two additional comparisons to handle a list double the size. The first comparison checks if the middle item is the sought item, the second comparison is to check whether the left or right half have to be searched next.\n",
    "\n",
    "**Activity:** What is a best case for binary search? What is its complexity? Test your hypothesis by changing the above experiments.\n",
    "\n",
    "**Activity:** What is a worst case for binary search? What is its complexity? Test your hypothesis by changing the above experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quadratic complexity\n",
    "\n",
    "An algorithm has quadratic complexity if its run-time quadruples when the input size doubles. A classic example is [bubble sort](https://en.wikipedia.org/wiki/Bubble_sort). The following paragraph and code are from [_The M269 Library_](http://tiny.cc/m269-library).\n",
    "\n",
    "The key insight is to swap adjacent items that are in the wrong order,\n",
    "until no swaps are possible: at that point the items are sorted.\n",
    "The algorithm divides a list of items into\n",
    "a left part (initially all items) of still unsorted items,\n",
    "and a right part (initially empty) of already sorted items.\n",
    "In each iteration, the algorithm goes through the unsorted part and\n",
    "swaps adjacent items that are in the wrong order.\n",
    "This 'bubbles' the largest item up to the sorted part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bubble_sort(items):\n",
    "    \"\"\"Sort the list of items in place, in non-decreasing order.\"\"\"\n",
    "    # To sort n items at most n-1 iterations are needed.\n",
    "    for iteration in range(1, len(items)):\n",
    "        swapped = False\n",
    "        # Each iteration shrinks the unsorted part by one.\n",
    "        # Go through the unsorted part.\n",
    "        for current in range(0, len(items) - iteration):\n",
    "            # Swap current and next item if they're in the wrong order.\n",
    "            this_item = items[current]\n",
    "            next_item = items[current + 1]\n",
    "            if this_item > next_item:\n",
    "                items[current] = next_item\n",
    "                items[current + 1] = this_item\n",
    "                swapped = True\n",
    "        # If no swaps were necessary, the items are sorted.\n",
    "        if not swapped:\n",
    "            return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best case is when the list is already in ascending order, as a single pass through the list determines that no swaps were done and the algorithm ends. The best case complexity is therefore linear.\n",
    "\n",
    "The worst case is when the list items are in the opposite order, i.e. descending order, as each item will have to bubble its way through all the other smaller items that come after it. \n",
    "\n",
    "The algorithm is quadratic in the worst case because the outer loop executes _n_ - 1 times, while the inner loop executes on average _n_ ÷ 2 times for _each_ outer iteration. So, the assignments and the comparison in the inner loop will be executed (_n_-1) x (_n_÷2) = (_n_<sup>2</sup> - _n_) ÷ 2 times. \n",
    "\n",
    "Quadratic algorithms take much longer than linear ones, so the input sizes should be kept reasonably small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.3 µs ± 96.1 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "numbers = [n for n in range(size, 0, -1)]\n",
    "%timeit bubble_sort(numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.4 µs ± 1.01 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "numbers = [n for n in range(size * 2, 0, -1)]\n",
    "%timeit bubble_sort(numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The times are not right; they suggest a linear complexity. The reason is that the sorting is done several times. The first call to the `bubble_sort` function sorts the list in quadratic time and the subsequent thousands of calls take much less time because they check it's sorted in linear time. \n",
    "\n",
    "Whenever your code changes the input, just execute it once, using the `-n` and `-r` parameters to set the number of loops and runs to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.44 ms ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "numbers = [n for n in range(size, 0, -1)]\n",
    "%timeit -n 1 -r 1 bubble_sort(numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.86 ms ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "numbers = [n for n in range(size * 2, 0, -1)]\n",
    "%timeit -n 1 -r 1 bubble_sort(numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we get the expected result: the time more or less quadrupled as the input size doubles.\n",
    "\n",
    "**Activity:** Executing a function only once results in less accurate timing, as it is more prone to variations due to the computer's processor being occupied with other tasks. Execute the above code cells several times (by pressing Ctrl-Enter on each cell) until obtaining consistent run-times."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
